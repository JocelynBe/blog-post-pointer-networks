{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# In order to ensure reproducibility, we set all the seeds manually.\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data, OCR and labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('documents.json', 'r') as f:\n",
    "    documents = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Retrieving documents content with an OCR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step is to extract the text from the images of the documents, along with there position. To do so, we leverage pytesseract here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import OCR\n",
    "\n",
    "for doc in tqdm(documents.values()):\n",
    "    doc['OCR'] = OCR(doc['image_path'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ground truth is a rectangle on the page that delimites where the ground is located. On the following example it is displayed in red, all the tokens transcribed by pytesseract are in blue."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import display_doc\n",
    "display_doc(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matching the ground truth to tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import ground_truth_match\n",
    "for doc in tqdm(documents.values()):\n",
    "    doc['labels'] = ground_truth_match(doc['OCR'], doc['ground_truth'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lengths = [\n",
    "    len(doc['labels'])\n",
    "    for doc in documents.values()\n",
    "]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(lengths)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We notice some outliers at 11 words, therefore we remove addresses where the number of matched tokens is higher than the number of words in the ground truth."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "failed_matching = []\n",
    "for key, doc in documents.items():\n",
    "    length_address = len(doc['address'].split())\n",
    "    if length_address != len(doc['labels']):\n",
    "        failed_matching.append(key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key in failed_matching:\n",
    "    del documents[key]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lengths = [\n",
    "    len(doc['labels'])\n",
    "    for doc in documents.values()\n",
    "]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(lengths)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-process data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text pre-processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import text_pre_processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\n",
    "        key,\n",
    "        [\n",
    "            (text_pre_processing(token['text']), token['position']) for token in doc['OCR']\n",
    "        ],\n",
    "        doc['labels']\n",
    "    )\n",
    "    for key, doc in documents.items()\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split train / validation / test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_DOCS = len(data)\n",
    "split = 60, 20, 20  # train / validation / test\n",
    "\n",
    "random.shuffle(data)\n",
    "n_train = int(split[0] / 100 * N_DOCS)\n",
    "n_val = n_train + int(split[1] / 100 * N_DOCS)\n",
    "\n",
    "dataset_split = {\n",
    "    'train': [doc for doc in data[:n_train]],\n",
    "    'validation': [doc for doc in data[n_train:n_val]],\n",
    "    'test': [doc for doc in data[n_val:]],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_split['train'][0][1][:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mapping the characters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "characters = set()\n",
    "for _, doc_input, _ in dataset_split['train']:\n",
    "    for word, _ in doc_input:\n",
    "        characters |= set([x for x in word])\n",
    "characters_mapping = {char: i + 1 for i, char in enumerate(characters)}  # + 1 to account for the stop token\n",
    "len(characters_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_split = {\n",
    "    mode: [\n",
    "        (\n",
    "            key,\n",
    "            (\n",
    "                [\n",
    "                    ([characters_mapping[c] for c in word], position)\n",
    "                    for word, position in input_data\n",
    "                ]\n",
    "            ),\n",
    "            target\n",
    "        )\n",
    "        for key, input_data, target in dataset_split[mode]\n",
    "    ]\n",
    "    for mode in dataset_split\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import make_tensors\n",
    "\n",
    "tensors_data = {}\n",
    "for mode in dataset_split:\n",
    "    tensors_data[mode] = make_tensors(dataset_split[mode])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for mode in tensors_data:\n",
    "    print('-'*40)\n",
    "    print('mode', mode)\n",
    "    print('words', tensors_data[mode]['words'].shape)\n",
    "    print('positions', tensors_data[mode]['positions'].shape)\n",
    "    print('target', tensors_data[mode]['target'].shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapping it up in a TensorDataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "datasets = {\n",
    "    mode: TensorDataset(\n",
    "            tensors_data[mode]['keys'],\n",
    "            tensors_data[mode]['words'].type(torch.LongTensor),\n",
    "            tensors_data[mode]['positions'],\n",
    "            tensors_data[mode]['target'].type(torch.LongTensor)\n",
    "        )\n",
    "    for mode in tensors_data\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensors_data[mode]['target'] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "embedding_dim = 64\n",
    "position_dim = 10\n",
    "max_seq_len = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    datasets['train'],\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    datasets['validation'],\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets['test'],\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Model(len(characters_mapping) + 1, embedding_dim, position_dim, max_seq_len)\n",
    "\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_epochs = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import train_model\n",
    "train_losses, val_losses = train_model(n_epochs, model, optimizer, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(train_losses, color='red', label=\"train\")\n",
    "plt.plot(val_losses, color='blue', label=\"validation\")\n",
    "plt.xlabel('n_epoch')\n",
    "plt.ylabel('cross_entropy_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Best val loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_step = np.argmin(val_losses)\n",
    "model = torch.load(f'models/model_{best_step}.torch')\n",
    "min(val_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Display prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for keys, words, positions, target in val_loader:\n",
    "    overall_probabilities, peak_indices = model.forward(words, positions)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import display_prediction\n",
    "\n",
    "key = keys[0].item()\n",
    "peaks = peak_indices[0].tolist()\n",
    "doc = documents[str(key)]\n",
    "display_prediction(doc, peaks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Thresholding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import get_threshold_data, get_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_threshold_data = get_threshold_data(model, optimizer, val_loader)\n",
    "get_metrics(val_threshold_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = val_threshold_data.loc[val_threshold_data.is_correct].confidence.values\n",
    "incorrect = val_threshold_data.loc[~val_threshold_data.is_correct].confidence.values\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(correct, bins=20, alpha=0.5, color='green', label='correct')\n",
    "plt.hist(incorrect, bins=20, alpha=0.5, color='red', label='incorrect')\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Number of documents per bucket')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_threshold_data = get_threshold_data(model, optimizer, test_loader)\n",
    "get_metrics(test_threshold_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = test_threshold_data.loc[test_threshold_data.is_correct].confidence.values\n",
    "incorrect = test_threshold_data.loc[~test_threshold_data.is_correct].confidence.values\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(correct, bins=20, alpha=0.5, color='green', label='correct')\n",
    "plt.hist(incorrect, bins=20, alpha=0.5, color='red', label='incorrect')\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Number of documents per bucket')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Automation and accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute threshold on validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import find_threshold\n",
    "\n",
    "target_accuracy = 0.99\n",
    "accuracies, automations, threshold_99acc = find_threshold(target_accuracy, val_threshold_data)\n",
    "\n",
    "thresholds = np.linspace(val_threshold_data.confidence.min(), 1, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot automation and accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(thresholds, automations, color='blue', label='automation')\n",
    "plt.plot(thresholds, accuracies, color='green', label='accuracy')\n",
    "plt.axvline(x=threshold_99acc, color='red', linestyle='--', label='0.99 threshold')\n",
    "plt.xlabel('Confidence score')\n",
    "plt.ylabel('Number of documents per bucket')\n",
    "plt.ylim(ymin=0.6)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get tet automation and test accuracy at the threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_above_threshold = test_threshold_data.loc[test_threshold_data.confidence > threshold_99acc]\n",
    "test_accuracy = test_above_threshold.is_correct.mean()\n",
    "test_automation = len(test_above_threshold)/len(test_threshold_data)\n",
    "test_accuracy, test_automation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threshold_99acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}